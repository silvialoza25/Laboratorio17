{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWre+oZLHZ+fRWgWPnYOp5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/ErickReyesData/dd86a90ba2373794b201c172efaca19b/ainductivo17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASIFICADOR RANDOM FOREST DE EVALUACIÓN DE VEHICULOS"
      ],
      "metadata": {
        "id": "vZKJAJXbsoGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest es un algoritmo de aprendizaje automático supervisado que se basa en el aprendizaje conjunto. En este núcleo, construyo dos modelos de clasificador de bosque aleatorio para predecir la seguridad del automóvil, uno con 10 árboles de decisión y otro con 100 árboles de decisión. La precisión esperada aumenta con el número de árboles de decisión en el modelo. He demostrado el proceso de selección de funciones utilizando el modelo Random Forest para encontrar solo las funciones importantes, reconstruir el modelo utilizando estas funciones y ver su efecto en la precisión."
      ],
      "metadata": {
        "id": "yyBW5OgQx4uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Cargar el archivo CSV usando pandas\n",
        "df = pd.read_csv('car_evaluation.csv')\n",
        "\n",
        "# Mostrar las primeras filas del dataset para verificar\n",
        "print(df.head())\n",
        "\n",
        "# Descripción del conjunto de datos\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "FVfWMJTaslLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, exploramos los datos para obtener información sobre ellos."
      ],
      "metadata": {
        "id": "C-6hjOxVyscC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view dimensions of dataset\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "kNJt34misyxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que hay 1728 instancias y 7 variables en el conjunto de datos."
      ],
      "metadata": {
        "id": "nzkgaCuxyuSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 5 del dataset"
      ],
      "metadata": {
        "id": "jUGEIn6ky2nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preview the dataset\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cvN2GO60s0eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiar el nombre de las columnas\n",
        "Podemos ver que el conjunto de datos no tiene nombres de columna adecuados. Las columnas están simplemente etiquetadas como 0,1,2... y así sucesivamente. Deberíamos dar nombres propios a las columnas. Lo hacemos asi:"
      ],
      "metadata": {
        "id": "Z-l9ihJ_y87E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "\n",
        "\n",
        "df.columns = col_names\n",
        "\n",
        "col_names"
      ],
      "metadata": {
        "id": "UlIJlQECs2LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aFqJzpB-s353"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que se cambia el nombre de los nombres de las columnas. Ahora las columnas tienen nombres significativos."
      ],
      "metadata": {
        "id": "q_SFHgWBzGOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver resumen del conjunto de datos"
      ],
      "metadata": {
        "id": "JHi166yVzRql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "U3fQiOhvs6YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribución de frecuencia de valores en variables.\n",
        "Ahora comprobamos los recuentos de frecuencia de las variables categóricas."
      ],
      "metadata": {
        "id": "U0X1lE49zaWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "\n",
        "\n",
        "for col in col_names:\n",
        "\n",
        "    print(df[col].value_counts())"
      ],
      "metadata": {
        "id": "T0MrhZcds701"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que las puertas y las personas son de naturaleza categórica. Por tanto, las tratamos como variables categóricas.\n",
        "\n",
        "Resumen de variables\n",
        "Hay 7 variables en el conjunto de datos. Todas las variables son de tipo de datos categóricos.\n",
        "Estos vienen dados por compra, mantenimiento, puertas, personas, maletero, seguridad y clase.\n",
        "la clase es la variable objetivo."
      ],
      "metadata": {
        "id": "you8v4GHzjcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploramos la variable Clase"
      ],
      "metadata": {
        "id": "s6R8PVupzrrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "id": "rywZbMvDs9p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variable objetivo de clase es de naturaleza ordinal.\n",
        "\n",
        "Valores faltantes en variables"
      ],
      "metadata": {
        "id": "sNcfimAgz6Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values in variables\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "cwvMF8xJtBe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que no faltan valores en el conjunto de datos. Hemos comprobado la distribución de frecuencia de los valores anteriormente. También confirma que no faltan valores en el conjunto de datos."
      ],
      "metadata": {
        "id": "SJ7GiTkZ0BM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declarar vector de características y variable de destino"
      ],
      "metadata": {
        "id": "OnLTroRS0Ono"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['class'], axis=1)\n",
        "\n",
        "y = df['class']"
      ],
      "metadata": {
        "id": "KnRZkL_ftB93"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividir los datos en conjuntos de prueba y entrenamiento separados"
      ],
      "metadata": {
        "id": "ptn2uhl40T_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ],
      "metadata": {
        "id": "D0-it69NtD52"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "PpSml5R0tFj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La ingeniería de funciones es el proceso de transformar datos sin procesar en funciones útiles que nos ayudan a comprender mejor nuestro modelo y aumentar su poder predictivo. Ejecutamos ingeniería de características sobre diferentes tipos de variables.\n",
        "\n",
        "Primero, revisamos nuevamente los tipos de datos de las variables."
      ],
      "metadata": {
        "id": "w-zl7BOE0fYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check data types in X_train\n",
        "\n",
        "X_train.dtypes"
      ],
      "metadata": {
        "id": "Gra9F7tZtHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codificar variables categóricas"
      ],
      "metadata": {
        "id": "tWy2-ncL0wEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "iagjh1qUtJum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que todas las variables son del tipo de datos categóricos ordinales."
      ],
      "metadata": {
        "id": "Ew5Hmwfo01g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import category encoders\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce"
      ],
      "metadata": {
        "id": "uJGUZ5LBtLRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical variables with ordinal encoding\n",
        "\n",
        "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
        "\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)"
      ],
      "metadata": {
        "id": "aI5GCHA8tNMn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "kdci2LTTtO03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "WlFiaBcxtQUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de clasificador de bosque aleatorio con parámetros predeterminados"
      ],
      "metadata": {
        "id": "gAIrU_Ap0_8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Random Forest classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "# instantiate the classifier\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# fit the model\n",
        "\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Predict the Test set results\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Check accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "qSFNOdNgtSMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, y_test son las etiquetas de clase verdaderas y y_pred son las etiquetas de clase previstas en el conjunto de pruebas.\n",
        "\n",
        "Aquí, se construye el modelo Clasificador de bosque aleatorio con el parámetro predeterminado de n_estimators = 10. Entonces, usamos 10 árboles de decisión para construir el modelo. Ahora, aumentamos la cantidad de árboles de decisión y vemos su efecto en la precisión."
      ],
      "metadata": {
        "id": "VIODtEwx1JJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de clasificador de bosque aleatorio con parámetro n_estimators=100"
      ],
      "metadata": {
        "id": "wJUtUw6s1Ud-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the classifier with n_estimators = 100\n",
        "\n",
        "rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "\n",
        "rfc_100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Predict on the test set results\n",
        "\n",
        "y_pred_100 = rfc_100.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Check accuracy score\n",
        "\n",
        "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
      ],
      "metadata": {
        "id": "dPnBgrUAtW9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentre características importantes con el modelo Random Forest"
      ],
      "metadata": {
        "id": "JcSPJNoC1mhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasta ahora, hemos utilizado todas las funciones proporcionadas en el modelo. Ahora, seleccionamos solo las características importantes, construimos el modelo usando estas características y vemos su efecto en la precisión.\n",
        "\n",
        "Primero, creamos el modelo de bosque aleatorio de la siguiente manera:"
      ],
      "metadata": {
        "id": "QaWbpyhb1oU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the classifier with n_estimators = 100\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "CPw0iYoAtuC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, usamos la variable de importancia de las características para ver las puntuaciones de importancia de las características."
      ],
      "metadata": {
        "id": "PLOa5L9C16Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view the feature scores\n",
        "\n",
        "feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "feature_scores"
      ],
      "metadata": {
        "id": "QabCZytctxJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que la característica más importante es la seguridad y la menos importante son las puertas."
      ],
      "metadata": {
        "id": "kuD0Aj6i2aeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizar puntuaciones de características de las características."
      ],
      "metadata": {
        "id": "417pbqit2a__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, visualizamos las puntuaciones de las funciones con matplotlib y seaborn."
      ],
      "metadata": {
        "id": "57IGRRjC2l9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a seaborn bar plot\n",
        "\n",
        "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
        "\n",
        "\n",
        "\n",
        "# Add labels to the graph\n",
        "\n",
        "plt.xlabel('Feature Importance Score')\n",
        "\n",
        "plt.ylabel('Features')\n",
        "\n",
        "\n",
        "\n",
        "# Add title to the graph\n",
        "\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "\n",
        "\n",
        "\n",
        "# Visualize the graph\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "po-TVUPUtyZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construya un modelo de bosque aleatorio en características seleccionadas"
      ],
      "metadata": {
        "id": "3bU9zlm12yRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, eliminamos las puertas de características menos importantes del modelo, reconstruimos el modelo y verificamos su efecto en la precisión."
      ],
      "metadata": {
        "id": "4wNNlBmU2y1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declare feature vector and target variable\n",
        "\n",
        "X = df.drop(['class', 'doors'], axis=1)\n",
        "\n",
        "y = df['class']"
      ],
      "metadata": {
        "id": "NjkVh_syt1TU"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ],
      "metadata": {
        "id": "KJCrFGMnt3JG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, construimos el modelo de bosque aleatorio y verificamos la precisión."
      ],
      "metadata": {
        "id": "0SWImUNI29Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical variables with ordinal encoding\n",
        "\n",
        "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'persons', 'lug_boot', 'safety'])\n",
        "\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)"
      ],
      "metadata": {
        "id": "Yewt82iRt46O"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the classifier with n_estimators = 100\n",
        "\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict on the test set results\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Check accuracy score\n",
        "\n",
        "print('Model accuracy score with doors variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "MCn3XAomt6uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quitamos la variable de puertas del modelo, la reconstruimos y verificamos su precisión. La precisión del modelo sin puertas variables es 0,9264. La precisión del modelo con todas las variables tomadas en cuenta es 0,9247. Entonces, podemos ver que la precisión del modelo se ha mejorado al eliminar la variable de puertas del modelo.\n",
        "\n",
        "Además, el segundo modelo menos importante es lug_boot. Si lo eliminamos del modelo y lo reconstruimos, la precisión es de 0,8546. Es una caída significativa en la precisión. Por lo tanto, no lo eliminamos del modelo.\n",
        "\n",
        "Ahora, según el análisis anterior, podemos concluir que la precisión de nuestro modelo de clasificación es muy buena. Nuestro modelo está haciendo un muy buen trabajo en términos de predecir las etiquetas de clase.\n",
        "\n",
        "Pero no proporciona la distribución subyacente de valores. Además, no dice nada sobre el tipo de errores que comete nuestro clasificador.\n",
        "\n",
        "Tenemos otra herramienta llamada Matriz de confusión que viene a nuestro rescate."
      ],
      "metadata": {
        "id": "v8iESZAO3Id6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix de Confusión"
      ],
      "metadata": {
        "id": "QS9nHRkz3dIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una matriz de confusión es una herramienta para resumir el desempeño de un algoritmo de clasificación. Una matriz de confusión nos dará una imagen clara del rendimiento del modelo de clasificación y los tipos de errores producidos por el modelo. Nos da un resumen de predicciones correctas e incorrectas desglosadas por cada categoría. El resumen se presenta en forma de tabla.\n",
        "\n",
        "Son posibles cuatro tipos de resultados al evaluar el desempeño de un modelo de clasificación. Estos cuatro resultados se describen a continuación: -\n",
        "\n",
        "Verdaderos positivos (TP): los verdaderos positivos ocurren cuando predecimos que una observación pertenece a una determinada clase y la observación en realidad pertenece a esa clase.\n",
        "\n",
        "Verdaderos Negativos (TN): Los Verdaderos Negativos ocurren cuando predecimos que una observación no pertenece a una determinada clase y la observación en realidad no pertenece a esa clase.\n",
        "\n",
        "Falsos positivos (FP): los falsos positivos ocurren cuando predecimos que una observación pertenece a una determinada clase, pero la observación en realidad no pertenece a esa clase. Este tipo de error se denomina error de tipo I.\n",
        "\n",
        "Falsos negativos (FN): los falsos negativos ocurren cuando predecimos que una observación no pertenece a una determinada clase, pero la observación en realidad pertenece a esa clase. Este es un error muy grave y se llama error de tipo II.\n",
        "\n",
        "Estos cuatro resultados se resumen en una matriz de confusión que se proporciona a continuación."
      ],
      "metadata": {
        "id": "UsgI5BEH3hbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxJFU5GAt8zC",
        "outputId": "2adbea41-4bcc-4262-c6b9-33da3319c549"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix\n",
            "\n",
            " [[108   5  12   2]\n",
            " [  1  10   2   5]\n",
            " [ 10   0 389   0]\n",
            " [  4   1   0  21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REPORTE DE CLASIFICACIÓN"
      ],
      "metadata": {
        "id": "JXOS4ZK830k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El informe de clasificación es otra forma de evaluar el rendimiento del modelo de clasificación. Muestra las puntuaciones de precisión, recuperación, f1 y soporte del modelo."
      ],
      "metadata": {
        "id": "YDaw2koj36Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3P0z-8X-t-1c",
        "outputId": "cda09d01-ad53-4156-cc21-09234918cfc0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         acc       0.88      0.85      0.86       127\n",
            "        good       0.62      0.56      0.59        18\n",
            "       unacc       0.97      0.97      0.97       399\n",
            "       vgood       0.75      0.81      0.78        26\n",
            "\n",
            "    accuracy                           0.93       570\n",
            "   macro avg       0.80      0.80      0.80       570\n",
            "weighted avg       0.93      0.93      0.93       570\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- En este proyecto, construimos un clasificador de bosque aleatorio para predecir la seguridad del automóvil. Construimos dos modelos, uno con 10 árboles de decisión y otro con 100 árboles de decisión.\n",
        "-La puntuación de precisión del modelo con 10 árboles de decisión es 0,9247, pero lo mismo con 100 árboles de decisión es 0,9457. Entonces, la precisión esperada aumenta con el número de árboles de decisión en el modelo.\n",
        "-Utilizamos el modelo Random Forest para encontrar solo las características importantes, construir el modelo usando estas características y ver su efecto en la precisión. La característica más importante es la seguridad y la menos importante son las puertas.\n",
        "-Quitamos la variable de puertas del modelo, la reconstruimos y verificamos su precisión. La precisión del modelo sin puertas variables es 0,9264. La precisión del modelo con todas las variables tomadas en cuenta es 0,9247. -Entonces, podemos ver que la precisión del modelo se ha mejorado al eliminar la variable de puertas del modelo.\n",
        "-El segundo modelo menos importante es lug_boot. Si lo eliminamos del modelo y lo reconstruimos, la precisión es de 0,8546. Es una caída significativa en la precisión. Por lo tanto, no lo eliminaremos del modelo.\n",
        "-La matriz de confusión y el informe de clasificación son otra herramienta para visualizar el rendimiento del modelo. Dan buen rendimiento."
      ],
      "metadata": {
        "id": "_hV5mVkl4B_u"
      }
    }
  ]
}